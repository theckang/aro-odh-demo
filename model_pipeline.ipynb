{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-file-datalake\n",
      "  Downloading azure_storage_file_datalake-12.3.0-py2.py3-none-any.whl (188 kB)\n",
      "\u001b[K     |████████████████████████████████| 188 kB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-identity\n",
      "  Downloading azure_identity-1.5.0-py2.py3-none-any.whl (103 kB)\n",
      "\u001b[K     |████████████████████████████████| 103 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-storage-blob\n",
      "  Downloading azure_storage_blob-12.8.0-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[K     |████████████████████████████████| 341 kB 7.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting msrest>=0.6.18\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 14.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-core<2.0.0,>=1.10.0\n",
      "  Downloading azure_core-1.12.0-py2.py3-none-any.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting msal<2.0.0,>=1.6.0\n",
      "  Downloading msal-1.10.0-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cryptography>=2.1.4\n",
      "  Downloading cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.6 in /opt/app-root/lib/python3.6/site-packages (from azure-identity) (1.14.0)\n",
      "Collecting msal-extensions~=0.3.0\n",
      "  Downloading msal_extensions-0.3.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 33.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: requests~=2.16 in /opt/app-root/lib/python3.6/site-packages (from msrest>=0.6.18->azure-storage-file-datalake) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.6/site-packages (from msrest>=0.6.18->azure-storage-file-datalake) (2019.11.28)\n",
      "Collecting PyJWT[crypto]<3,>=1.0.0\n",
      "  Downloading PyJWT-2.0.1-py3-none-any.whl (15 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "\u001b[K     |████████████████████████████████| 401 kB 46.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 43.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /opt/app-root/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.6.18->azure-storage-file-datalake) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/app-root/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.6.18->azure-storage-file-datalake) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/app-root/lib/python3.6/site-packages (from requests~=2.16->msrest>=0.6.18->azure-storage-file-datalake) (1.25.8)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 27.9 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: isodate, oauthlib, requests-oauthlib, msrest, pycparser, cffi, cryptography, azure-core, azure-storage-blob, azure-storage-file-datalake, PyJWT, msal, portalocker, msal-extensions, azure-identity\n",
      "Successfully installed PyJWT-2.0.1 azure-core-1.12.0 azure-identity-1.5.0 azure-storage-blob-12.8.0 azure-storage-file-datalake-12.3.0 cffi-1.14.5 cryptography-3.4.6 isodate-0.6.0 msal-1.10.0 msal-extensions-0.3.0 msrest-0.6.21 oauthlib-3.1.0 portalocker-1.7.1 pycparser-2.20 requests-oauthlib-1.3.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/opt/app-root/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-file-datalake azure-identity azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, uuid, sys\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.core._match_conditions import MatchConditions\n",
    "from azure.storage.filedatalake._models import ContentSettings\n",
    "\n",
    "def initialize_storage_account_ad(storage_account_name, client_id, client_secret, tenant_id):\n",
    "    \n",
    "    try:  \n",
    "        global service_client\n",
    "\n",
    "        credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
    "\n",
    "        service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
    "            \"https\", storage_account_name), credential=credential)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def download_file_from_directory():\n",
    "    try:\n",
    "        file_system_client = service_client.get_file_system_client(file_system=\"mycontainer\")\n",
    "        directory_client = file_system_client.get_directory_client(\"sample\")\n",
    "        \n",
    "        local_file = open(\"iris.data\",'wb')\n",
    "\n",
    "        file_client = directory_client.get_file_client(\"iris.data\")\n",
    "\n",
    "        download = file_client.download_file()\n",
    "\n",
    "        downloaded_bytes = download.readall()\n",
    "\n",
    "        local_file.write(downloaded_bytes)\n",
    "\n",
    "        local_file.close()\n",
    "\n",
    "    except Exception as e:\n",
    "     print(e)\n",
    "\n",
    "# Enter service principal credentials with access to storage account\n",
    "storage_account_name = \"\"\n",
    "client_id = \"\"\n",
    "client_secret = \"\"\n",
    "tenant_id = \"\"\n",
    "\n",
    "# Initialize and download dataset\n",
    "initialize_storage_account_ad(storage_account_name, client_id, client_secret, tenant_id)\n",
    "download_file_from_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]]\n",
      "[0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Read training data set\n",
    "train_df = pd.read_csv(\"iris.data\", header=None, names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "y = pd.factorize(train_df[\"class\"])[0]\n",
    "\n",
    "train_df.pop(\"class\")\n",
    "X = train_df.values\n",
    "\n",
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Test model\n",
    "print(X[0:2])\n",
    "print(clf.predict(X[0:2]))\n",
    "\n",
    "# Save model to local disk\n",
    "dump(clf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uploading to Azure Storage as blob:\n",
      "\tsklearn/model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save model to Azure blob storage\n",
    "\n",
    "import os, uuid\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
    "\n",
    "container_name = \"mycontainer\"\n",
    "local_file_name = \"model.joblib\"\n",
    "upload_path = \"sklearn/model.joblib\"\n",
    "\n",
    "try:\n",
    "    connect_str = \"\"\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=upload_path)\n",
    "\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + upload_path)\n",
    "\n",
    "    # Upload the created file\n",
    "    with open(local_file_name, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print('Exception:')\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100 23.2M  100 23.2M    0     0  38.9M      0 --:--:-- --:--:-- --:--:-- 38.9M\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -O https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.6/linux/oc.tar.gz\n",
    "tar xzf oc.tar.gz\n",
    "cp oc /opt/app-root/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into \"https://openshift.default.svc.cluster.local:443\" as \"kube:admin\" using the token provided.\n",
      "\n",
      "You have access to 68 projects, the list has been suppressed. You can list all projects with ' projects'\n",
      "\n",
      "Using project \"default\".\n",
      "seldondeployment.machinelearning.seldon.io/example created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Configure anonymous access to blob container\n",
    "# https://docs.microsoft.com/en-us/azure/storage/blobs/anonymous-read-access-configure?tabs=portal\n",
    "\n",
    "# Test oc\n",
    "oc login --server https://openshift.default.svc.cluster.local --insecure-skip-tls-verify --token=\n",
    "\n",
    "# Run model in Seldon\n",
    "oc apply -n odh -f - <<EOF\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: example\n",
    "spec:\n",
    "  name: iris\n",
    "  predictors:\n",
    "    - graph:\n",
    "        children: []\n",
    "        implementation: SKLEARN_SERVER\n",
    "        modelUri: https://datalake555.blob.core.windows.net/mycontainer/sklearn/model.joblib\n",
    "        name: classifier\n",
    "      name: default\n",
    "      replicas: 1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"names\":[\"t:0\",\"t:1\",\"t:2\"],\"ndarray\":[[0.035372518282028136,0.006231902938911814,0.95839557877906]]},\"meta\":{\"requestPath\":{\"classifier\":\"registry.connect.redhat.com/seldonio/sklearnserver@sha256:1155a06aa8903e8436aaccbad64bd864a4a480b625466f6033dd08af7748d42a\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   313  100   275  100    38   2024    279 --:--:-- --:--:-- --:--:--  2037\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Test model in Seldon\n",
    "MODEL_URL=example-default.odh.svc.cluster.local:8000\n",
    "curl -X POST $MODEL_URL/api/v1.0/predictions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -d '{ \"data\": { \"ndarray\": [[1,2,3,4]] } }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
