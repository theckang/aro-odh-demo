{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install old version of scikit-learn, see https://github.com/SeldonIO/seldon-core/issues/2059\n",
    "!pip install -UIv scikit-learn==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-storage-file-datalake azure-identity azure-storage-blob pandas joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ENTER YOUR DETAILS  ###\n",
    "\n",
    "storage_account_name = \"\"\n",
    "client_id = \"\"\n",
    "tenant_id = \"\"\n",
    "client_secret = \"\"                                      # client secret value of the service principal\n",
    "connection_string = \"\"                                  # blob storage connection string\n",
    "\n",
    "# run `oc whoami --show-token` to get your token\n",
    "# do not use quotes\n",
    "%env OPENSHIFT_TOKEN=\n",
    "%env STORAGE_ACCOUNT_NAME="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "from azure.identity import ClientSecretCredential\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.core._match_conditions import MatchConditions\n",
    "from azure.storage.filedatalake._models import ContentSettings\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
    "\n",
    "def initialize_storage_account_ad(storage_account_name, client_id, client_secret, tenant_id):\n",
    "    \n",
    "    try:  \n",
    "        global service_client\n",
    "\n",
    "        credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
    "\n",
    "        service_client = DataLakeServiceClient(account_url=\"{}://{}.dfs.core.windows.net\".format(\n",
    "            \"https\", storage_account_name), credential=credential)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "def download_file_from_directory(dataset):\n",
    "    try:\n",
    "        file_system_client = service_client.get_file_system_client(file_system=\"mycontainer\")\n",
    "        directory_client = file_system_client.get_directory_client(\"sample\")\n",
    "        \n",
    "        local_file = open(dataset,'wb')\n",
    "\n",
    "        file_client = directory_client.get_file_client(dataset)\n",
    "\n",
    "        download = file_client.download_file()\n",
    "\n",
    "        downloaded_bytes = download.readall()\n",
    "\n",
    "        local_file.write(downloaded_bytes)\n",
    "\n",
    "        local_file.close()\n",
    "\n",
    "    except Exception as e:\n",
    "     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and download Iris dataset from Azure Data Lake\n",
    "initialize_storage_account_ad(storage_account_name, client_id, client_secret, tenant_id)\n",
    "download_file_from_directory(\"iris.data\")\n",
    "\n",
    "# Read training data set\n",
    "train_df = pd.read_csv(\"iris.data\", header=None, names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "y = pd.factorize(train_df[\"class\"])[0]\n",
    "train_df.pop(\"class\")\n",
    "X = train_df.values\n",
    "\n",
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X,y)\n",
    "\n",
    "# Test model\n",
    "print(X[0:2])\n",
    "print(clf.predict(X[0:2]))\n",
    "\n",
    "# Save model to local disk\n",
    "dump(clf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to Azure Blob Storage\n",
    "local_file_name = \"model.joblib\"\n",
    "upload_path = \"sklearn/model.joblib\"\n",
    "\n",
    "try:\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    blob_client = blob_service_client.get_blob_client(container=\"mycontainer\", blob=upload_path)\n",
    "\n",
    "    print(\"\\nUploading to Azure Storage as blob:\\n\\t\" + upload_path)\n",
    "\n",
    "    # Upload the created file\n",
    "    with open(local_file_name, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "    \n",
    "except Exception as ex:\n",
    "    print('Exception:')\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -O https://mirror.openshift.com/pub/openshift-v4/clients/oc/4.6/linux/oc.tar.gz\n",
    "tar xzf oc.tar.gz\n",
    "cp oc /opt/app-root/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Test oc\n",
    "oc login --server https://openshift.default.svc.cluster.local --insecure-skip-tls-verify --token=$OPENSHIFT_TOKEN\n",
    "\n",
    "# Run model in Seldon\n",
    "oc apply -n odh -f - <<EOF\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: example\n",
    "spec:\n",
    "  name: iris\n",
    "  predictors:\n",
    "    - graph:\n",
    "        children: []\n",
    "        implementation: SKLEARN_SERVER\n",
    "        modelUri: https://$STORAGE_ACCOUNT_NAME.blob.core.windows.net/mycontainer/sklearn/model.joblib\n",
    "        name: classifier\n",
    "      name: default\n",
    "      replicas: 1\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Test model in Seldon\n",
    "MODEL_URL=example-default.odh.svc.cluster.local:8000\n",
    "curl -X POST $MODEL_URL/api/v1.0/predictions \\\n",
    "    -H 'Content-Type: application/json' \\\n",
    "    -d '{ \"data\": { \"ndarray\": [[1,2,3,4]] } }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
